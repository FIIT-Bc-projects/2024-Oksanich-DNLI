{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"flwr[simulation]\" flwr-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7192138a-8c87-4d9a-f726-af1038ad264c"
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.13.1+cpu torchvision==0.14.1+cpu --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "58b7af77-609f-4118-bd5b-5629a4b5a296"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:47:36.634895Z",
     "start_time": "2024-10-17T21:47:35.908558Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:17:00.168980Z",
     "start_time": "2024-10-17T21:17:00.157976Z"
    }
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[[\"sentence\", \"gold_label\"]].rename(columns={\"sentence\": \"text\", \"gold_label\": \"label\"})\n",
    "    df = df[df.label != \"mixed\"].dropna()\n",
    "    df[\"label\"] = df[\"label\"].map(label_mapping)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(ds: Dataset, tokenizer: PreTrainedTokenizer) -> pd.DataFrame:\n",
    "    ds = ds.map(\n",
    "        lambda s, tok: {\n",
    "            \"ids\": (encoded := tok(s[\"text\"], truncation=True, padding=True))[\"input_ids\"],\n",
    "            \"attention_mask\": encoded[\"attention_mask\"],\n",
    "        },\n",
    "        fn_kwargs={\"tok\": tokenizer},\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = preprocess_data(pd.read_json(\"data/dynasent-v1.1-round01-yelp-train.jsonl\", lines=True))\n",
    "validation_data = pd.concat([\n",
    "    preprocess_data(pd.read_json(\"data/dynasent-v1.1-round01-yelp-test.jsonl\", lines=True)),\n",
    "    preprocess_data(pd.read_json(\"data/dynasent-v1.1-round01-yelp-dev.jsonl\", lines=True)),\n",
    "], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint_data = pd.concat([training_data, validation_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data, validation_data = train_test_split(joint_data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = Dataset.from_pandas(training_data, preserve_index=False)\n",
    "validation_ds = Dataset.from_pandas(validation_data, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:24:40.005598Z",
     "start_time": "2024-10-17T21:23:57.018099Z"
    }
   },
   "outputs": [],
   "source": [
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:24:40.005598Z",
     "start_time": "2024-10-17T21:23:57.018099Z"
    }
   },
   "outputs": [],
   "source": [
    "training_ds = tokenize_data(training_ds, distilbert_tokenizer)\n",
    "validation_ds = tokenize_data(validation_ds, distilbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:24:40.005598Z",
     "start_time": "2024-10-17T21:23:57.018099Z"
    }
   },
   "outputs": [],
   "source": [
    "training_ds = training_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"attention_mask\"])\n",
    "validation_ds = validation_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:28:59.065437Z",
     "start_time": "2024-10-17T21:28:59.053432Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetDict({\"train\": training_ds, \"test\": validation_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:45:20.178640Z",
     "start_time": "2024-10-16T14:45:20.169742Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f10b649f-3cee-4e86-c7ff-94bd1fd3e082"
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset: Dataset, batch_size: int, pad_index, shuffle=False) -> DataLoader:\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = nn.utils.rnn.pad_sequence([i[\"ids\"] for i in batch], padding_value=pad_index, batch_first=True)\n",
    "        batch_label = torch.stack([i[\"label\"] for i in batch])\n",
    "        batch_mask = nn.utils.rnn.pad_sequence([i[\"attention_mask\"] for i in batch], padding_value=pad_index, batch_first=True)\n",
    "        \n",
    "        return {\n",
    "            \"ids\": batch_ids,\n",
    "            \"label\": batch_label,\n",
    "            \"attention_mask\": batch_mask,\n",
    "        }\n",
    "    \n",
    "    dl = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:45:20.178640Z",
     "start_time": "2024-10-16T14:45:20.169742Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f10b649f-3cee-4e86-c7ff-94bd1fd3e082"
   },
   "outputs": [],
   "source": [
    "training_dl = get_data_loader(training_ds, 32, distilbert_tokenizer.pad_token_id, shuffle=True)\n",
    "validation_dl = get_data_loader(validation_ds, 32, distilbert_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:50:57.230181Z",
     "start_time": "2024-10-16T14:50:57.223058Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, transformer, num_classes: int, freeze: bool):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = transformer\n",
    "        self.fc = nn.Linear(transformer.config.hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    \n",
    "    def forward(self, ids: torch.Tensor, attention_mask: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        output = self.transformer(ids, attention_mask=attention_mask, output_attentions=True)\n",
    "        pooled_mean = torch.mean(output.last_hidden_state, dim=1)\n",
    "        cls_hidden = self.dropout(pooled_mean)\n",
    "        prediction = self.fc(cls_hidden)\n",
    "\n",
    "        return prediction, output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_tf = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "model = Transformer(distilbert_tf, num_classes=3, freeze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from backup\n",
    "### Checkpoint loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th epoch\n",
    "checkpoint = torch.load(\"model/checkpoint5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model/trained_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = sum(value.numel() for value in model.state_dict().values())\n",
    "print(f\"{num_parameters = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:51:11.813641Z",
     "start_time": "2024-10-16T14:51:10.449494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67d01ab4-cdd9-4661-8f01-eaa9aabf786d"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:00:12.945813Z",
     "start_time": "2024-10-10T11:00:12.935392Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label) -> np.float64:\n",
    "    predicted_classes = prediction.argmax(dim=-1).cpu().numpy()\n",
    "    actual_labels = label.cpu().numpy()\n",
    "    \n",
    "    return accuracy_score(actual_labels, predicted_classes)\n",
    "\n",
    "def get_precision(prediction, label) -> np.float64:\n",
    "    predicted_classes = prediction.argmax(dim=-1).cpu().numpy()\n",
    "    actual_labels = label.cpu().numpy()\n",
    "    \n",
    "    return precision_score(actual_labels, predicted_classes, average=\"macro\", zero_division=0)\n",
    "\n",
    "def get_recall(prediction, label) -> np.float64:\n",
    "    predicted_classes = prediction.argmax(dim=-1).cpu().numpy()\n",
    "    actual_labels = label.cpu().numpy()\n",
    "    \n",
    "    return recall_score(actual_labels, predicted_classes, average=\"macro\", zero_division=0)\n",
    "\n",
    "def get_f1_score(precision: np.float64, recall: np.float64) -> np.float64:\n",
    "    return np.float64(2.0) * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "        net: Transformer,\n",
    "        data_loader: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    ") -> tuple[np.float64, np.float64, np.float64, np.float64, np.float64]:\n",
    "    net.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_accuracies = []\n",
    "    batch_precisions = []\n",
    "    batch_recalls = []\n",
    "    \n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"Training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        prediction, _ = net(ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        precision = get_precision(prediction, label)\n",
    "        recall = get_recall(prediction, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_losses.append(loss)\n",
    "        batch_accuracies.append(accuracy)\n",
    "        batch_precisions.append(precision)\n",
    "        batch_recalls.append(recall)\n",
    "\n",
    "    avg_loss = np.mean(batch_losses)\n",
    "    avg_accuracy = np.mean(batch_accuracies)\n",
    "    avg_precision = np.mean(batch_precisions)\n",
    "    avg_recall = np.mean(batch_recalls)\n",
    "    f1_score = get_f1_score(avg_precision, avg_recall)\n",
    "        \n",
    "    return avg_loss, avg_accuracy, avg_precision, avg_recall, f1_score\n",
    "\n",
    "def test(\n",
    "        net: Transformer,\n",
    "        data_loader: DataLoader,\n",
    ") -> tuple[np.float64, np.float64, np.float64, np.float64, np.float64]:\n",
    "    net.eval()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_accuracies = []\n",
    "    batch_precisions = []\n",
    "    batch_recalls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"Evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            \n",
    "            prediction, _ = net(ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            precision = get_precision(prediction, label)\n",
    "            recall = get_recall(prediction, label)\n",
    "            \n",
    "            batch_losses.append(loss)\n",
    "            batch_accuracies.append(accuracy)\n",
    "            batch_precisions.append(precision)\n",
    "            batch_recalls.append(recall)\n",
    "\n",
    "    avg_loss = np.mean(batch_losses)\n",
    "    avg_accuracy = np.mean(batch_accuracies)\n",
    "    avg_precision = np.mean(batch_precisions)\n",
    "    avg_recall = np.mean(batch_recalls)\n",
    "    f1_score = get_f1_score(avg_precision, avg_recall)\n",
    "            \n",
    "    return avg_loss, avg_accuracy, avg_precision, avg_recall, f1_score\n",
    "\n",
    "def run_centralized(\n",
    "        training_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "        epochs: int,\n",
    "        learning_rate: float,\n",
    "        save_checkpoints: bool,\n",
    "        first_epoch: int = 0,\n",
    "        optimizer_state_dict = None,\n",
    ") -> dict[str, dict[str, list[np.float64]]]:\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_precisions = []\n",
    "    train_recalls = []\n",
    "    train_f1_scores = []\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_precisions = []\n",
    "    test_recalls = []\n",
    "    test_f1_scores = []\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if optimizer_state_dict:\n",
    "        optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "    for epoch in range(first_epoch, epochs):\n",
    "        print(f\"Training epoch #{epoch + 1}:\")\n",
    "        \n",
    "        train_loss, train_accuracy, train_precision, train_recall, train_f1_score = train(model, training_loader, optimizer)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_precisions.append(train_precision)\n",
    "        train_recalls.append(train_recall)\n",
    "        train_f1_scores.append(train_f1_score)\n",
    "\n",
    "        print(f\"{train_loss = }\")\n",
    "        print(f\"{train_accuracy = }\")\n",
    "        print(f\"{train_precision = }\")\n",
    "        print(f\"{train_recall = }\")\n",
    "        print(f\"{train_f1_score = }\")\n",
    "\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_f1_score = test(model, validation_loader)\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        test_precisions.append(test_precision)\n",
    "        test_recalls.append(test_recall)\n",
    "        test_f1_scores.append(test_f1_score)\n",
    "\n",
    "        print(f\"{test_loss = }\")\n",
    "        print(f\"{test_accuracy = }\")\n",
    "        print(f\"{test_precision = }\")\n",
    "        print(f\"{test_recall = }\")\n",
    "        print(f\"{test_f1_score = }\")\n",
    "        \n",
    "        if save_checkpoints:\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train\": {\n",
    "                    \"loss\": train_losses,\n",
    "                    \"accuracy\": train_accuracies,\n",
    "                    \"precision\": train_precisions,\n",
    "                    \"recall\": train_recalls,\n",
    "                    \"f1_score\": train_f1_scores,\n",
    "                },\n",
    "                \"test\": {\n",
    "                    \"loss\": test_losses,\n",
    "                    \"accuracy\": test_accuracies,\n",
    "                    \"precision\": test_precisions,\n",
    "                    \"recall\": test_recalls,\n",
    "                    \"f1_score\": test_f1_scores,\n",
    "                },\n",
    "            }, f\"model/checkpoint{epoch}.pth\")\n",
    "            \n",
    "    return {\n",
    "        \"train\": {\n",
    "            \"loss\": train_losses,\n",
    "            \"accuracy\": train_accuracies,\n",
    "            \"precision\": train_precisions,\n",
    "            \"recall\": train_recalls,\n",
    "            \"f1_score\": train_f1_scores,\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"loss\": test_losses,\n",
    "            \"accuracy\": test_accuracies,\n",
    "            \"precision\": test_precisions,\n",
    "            \"recall\": test_recalls,\n",
    "            \"f1_score\": test_f1_scores,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:05:21.280347Z",
     "start_time": "2024-10-10T11:00:21.410957Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8d9b429-178d-4924-e82f-4d4e52863788"
   },
   "outputs": [],
   "source": [
    "n = 6\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:05:21.280347Z",
     "start_time": "2024-10-10T11:00:21.410957Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8d9b429-178d-4924-e82f-4d4e52863788"
   },
   "outputs": [],
   "source": [
    "metrics = run_centralized(\n",
    "    training_dl,\n",
    "    validation_dl,\n",
    "    epochs=n,\n",
    "    learning_rate=lr,\n",
    "    save_checkpoints=True,\n",
    "    #first_epoch=checkpoint[\"epoch\"],\n",
    "    #optimizer_state_dict=checkpoint[\"optimizer_state_dict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on 10 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "random_indices = random.sample(range(0, len(validation_ds)), 10)\n",
    "\n",
    "texts = [validation_ds['text'][i] for i in random_indices]\n",
    "labels = [validation_ds['label'][i].item() for i in random_indices]\n",
    "predictions = []\n",
    "\n",
    "prediction_sample = get_data_loader(Subset(validation_ds, random_indices), 1, distilbert_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    \n",
    "    for batch in prediction_sample:\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        prediction, _ = model(ids, attention_mask)\n",
    "        predicted_class = prediction.argmax(dim=-1)\n",
    "\n",
    "        predictions.append(predicted_class.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list(zip(texts, [reverse_mapping[l] for l in labels], [reverse_mapping[p] for p in predictions])):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_rng = range(1, n + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_rng, metrics[\"train\"][\"loss\"], label=\"Training\", color=\"yellow\")\n",
    "plt.plot(epoch_rng, metrics[\"test\"][\"loss\"], label=\"Validation\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model Loss Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_rng, metrics[\"train\"][\"accuracy\"], label=\"Training\", color=\"yellow\")\n",
    "plt.plot(epoch_rng, metrics[\"test\"][\"accuracy\"], label=\"Validation\", color=\"blue\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model Accuracy Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_rng, metrics[\"train\"][\"precision\"], label=\"Training\", color=\"yellow\")\n",
    "plt.plot(epoch_rng, metrics[\"test\"][\"precision\"], label=\"Validation\", color=\"green\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model Precision Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_rng, metrics[\"train\"][\"recall\"], label=\"Training\", color=\"yellow\")\n",
    "plt.plot(epoch_rng, metrics[\"test\"][\"recall\"], label=\"Validation\", color=\"purple\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model Recall Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_rng, metrics[\"train\"][\"f1_score\"], label=\"Training\", color=\"yellow\")\n",
    "plt.plot(epoch_rng, metrics[\"test\"][\"f1_score\"], label=\"Validation\", color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model F1 Score Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
