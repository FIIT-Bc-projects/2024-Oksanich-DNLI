{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"flwr[simulation]\" flwr-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7192138a-8c87-4d9a-f726-af1038ad264c"
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.13.1+cpu torchvision==0.14.1+cpu --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "58b7af77-609f-4118-bd5b-5629a4b5a296"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:47:36.634895Z",
     "start_time": "2024-10-17T21:47:35.908558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oksanich/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:17:00.168980Z",
     "start_time": "2024-10-17T21:17:00.157976Z"
    }
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"Negative\": 0,\n",
    "    \"Neutral\": 1,\n",
    "    \"Positive\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:22:36.560218Z",
     "start_time": "2024-10-17T21:22:35.753677Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"data/twitter_training.csv\", names=[\"tweet_id\", \"entity\", \"label\", \"text\"])\n",
    "training_data = training_data[training_data.label != \"Irrelevant\"].drop(columns=[\"tweet_id\", \"entity\"]).dropna()\n",
    "training_data[\"label\"] = training_data[\"label\"].map(label_mapping)\n",
    "training_ds = Dataset.from_pandas(training_data, preserve_index=False)\n",
    "\n",
    "validation_data = pd.read_csv(\"data/twitter_validation.csv\", names=[\"tweet_id\", \"entity\", \"label\", \"text\"])\n",
    "validation_data = validation_data[validation_data.label != \"Irrelevant\"].drop(columns=[\"tweet_id\", \"entity\"]).dropna()\n",
    "validation_data[\"label\"] = validation_data[\"label\"].map(label_mapping)\n",
    "validation_ds = Dataset.from_pandas(validation_data, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:24:40.005598Z",
     "start_time": "2024-10-17T21:23:57.018099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████| 61121/61121 [00:09<00:00, 6657.85 examples/s]\n",
      "Map: 100%|███████████████████████████| 828/828 [00:00<00:00, 5914.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "pad = tokenizer.pad_token_id\n",
    "\n",
    "training_ds = training_ds.map(lambda s, t: {\"ids\": t(s[\"text\"], truncation=True)[\"input_ids\"]}, fn_kwargs={\"t\": tokenizer})\n",
    "validation_ds = validation_ds.map(lambda s, t: {\"ids\": t(s[\"text\"], truncation=True)[\"input_ids\"]}, fn_kwargs={\"t\": tokenizer})\n",
    "\n",
    "training_ds = training_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\"])\n",
    "validation_ds = validation_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:28:59.065437Z",
     "start_time": "2024-10-17T21:28:59.053432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'ids'],\n",
       "        num_rows: 61121\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'ids'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetDict({\"train\": training_ds, \"test\": validation_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:45:20.178640Z",
     "start_time": "2024-10-16T14:45:20.169742Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f10b649f-3cee-4e86-c7ff-94bd1fd3e082"
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = nn.utils.rnn.pad_sequence([i[\"ids\"] for i in batch], padding_value=pad_index, batch_first=True)\n",
    "        \n",
    "        batch_label = [i[\"label\"] for i in batch]\n",
    "        batch_label = torch.stack(batch_label)\n",
    "        \n",
    "        return {\n",
    "            \"ids\": batch_ids,\n",
    "            \"label\": batch_label\n",
    "        }\n",
    "    \n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    return dl\n",
    "\n",
    "training_dl = get_data_loader(training_ds, 32, pad, shuffle=True)\n",
    "validation_dl = get_data_loader(validation_ds, 32, pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:50:57.230181Z",
     "start_time": "2024-10-16T14:50:57.223058Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, transformer, num_classes, freeze):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = transformer\n",
    "        self.fc = nn.Linear(transformer.config.hidden_size, num_classes)\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "    def forward(self, ids: torch.Tensor) -> torch.Tensor:\n",
    "        output = self.transformer(ids, output_attentions=True)\n",
    "        \n",
    "        cls_hidden = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        prediction = self.fc(torch.tanh(cls_hidden))\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = Transformer(tf, num_classes=3, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model/trained_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_parameters = 109484547\n"
     ]
    }
   ],
   "source": [
    "num_parameters = sum(value.numel() for value in model.state_dict().values())\n",
    "\n",
    "print(f\"{num_parameters = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:51:11.813641Z",
     "start_time": "2024-10-16T14:51:10.449494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67d01ab4-cdd9-4661-8f01-eaa9aabf786d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (transformer): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:00:12.945813Z",
     "start_time": "2024-10-10T11:00:12.935392Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def train(net, data_loader, optimizer, crit=criterion):\n",
    "    net.train()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"Training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = net(ids)\n",
    "        loss = crit(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accuracies.append(accuracy.item())\n",
    "        \n",
    "    return np.mean(epoch_losses), np.mean(epoch_accuracies)\n",
    "\n",
    "def test(net, data_loader):\n",
    "    net.eval()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"Evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = net(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accuracies.append(accuracy.item())\n",
    "            \n",
    "    return np.mean(epoch_losses), np.mean(epoch_accuracies)\n",
    "\n",
    "def run_centralized(\n",
    "        training_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "        epochs: int,\n",
    "        learning_rate: float,\n",
    "        save_checkpoints: bool\n",
    "):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Training epoch #{epoch + 1}:\")\n",
    "        \n",
    "        train(model, training_loader, optimizer)\n",
    "\n",
    "        loss, accuracy = test(model, validation_loader)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"{loss = }\")\n",
    "        print(f\"{accuracy = }\")\n",
    "        \n",
    "        if save_checkpoints:\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"accuracy\": accuracy\n",
    "            }, \"model/checkpoint.pth\")\n",
    "            \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:05:21.280347Z",
     "start_time": "2024-10-10T11:00:21.410957Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8d9b429-178d-4924-e82f-4d4e52863788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch #1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|                                     | 0/1911 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Training...: 100%|████████████████████████| 1911/1911 [2:40:40<00:00,  5.04s/it]\n",
      "Evaluating...: 100%|████████████████████████████| 26/26 [00:42<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.2969047622038768\n",
      "accuracy = 0.8916552204352158\n",
      "Training epoch #2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|████████████████████████| 1911/1911 [2:41:24<00:00,  5.07s/it]\n",
      "Evaluating...: 100%|████████████████████████████| 26/26 [00:42<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.11718718200707091\n",
      "accuracy = 0.9579326923076923\n",
      "Training epoch #3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|████████████████████████| 1911/1911 [2:41:33<00:00,  5.07s/it]\n",
      "Evaluating...: 100%|████████████████████████████| 26/26 [00:42<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.09005720654609971\n",
      "accuracy = 0.9759615384615384\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "lr = 1e-5\n",
    "\n",
    "l, a = run_centralized(training_dl, validation_dl, epochs=n, learning_rate=lr, save_checkpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_rng = range(1, n + 1)\n",
    "\n",
    "plt.plot(epoch_rng, l, label=\"Loss\", color=\"red\")\n",
    "plt.plot(epoch_rng, a, label=\"Accuracy\", color=\"blue\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.title(\"Model Evaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:17:39.868368Z",
     "start_time": "2024-10-16T18:17:39.858380Z"
    }
   },
   "outputs": [],
   "source": [
    "partitioner = IidPartitioner(num_partitions=10)\n",
    "partitioner.dataset = training_ds\n",
    "\n",
    "partitioner.load_partition(partition_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:29:13.119824Z",
     "start_time": "2024-10-16T18:29:12.484470Z"
    }
   },
   "outputs": [],
   "source": [
    "from flwr_datasets.visualization import plot_label_distributions\n",
    "\n",
    "fig, ax, df = plot_label_distributions(\n",
    "    partitioner,\n",
    "    label_name=\"label\",\n",
    "    plot_type=\"bar\",\n",
    "    size_unit=\"absolute\",\n",
    "    partition_id_axis=\"x\",\n",
    "    legend=True,\n",
    "    verbose_labels=False,\n",
    "    max_num_partitions=10,\n",
    "    title=\"Label Distribution Per Partition\",\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from flwr.client import NumPyClient\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, training_loader, validation_loader) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.training_loader = training_loader\n",
    "        self.validation_loader = validation_loader\n",
    "\n",
    "        self.tf = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model = Transformer(tf, num_classes=3, freeze=False)\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = self.model.to(device)\n",
    "        self.criterion = self.criterion.to(device)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_params(self.model, parameters)\n",
    "\n",
    "        optim = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "\n",
    "        loss, accuracy = train(self.model, self.training_loader, optim, self.criterion)\n",
    "\n",
    "        return get_params(self.model), len(self.training_loader), {\"loss\": loss, \"accuracy\": accuracy}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "        set_params(self.model, parameters)\n",
    "        \n",
    "        loss, accuracy = test(self.model, self.validation_loader)\n",
    "        \n",
    "        return float(loss), len(self.validation_loader), {\"accuracy\": accuracy}\n",
    "\n",
    "def set_params(ml_model, parameters):\n",
    "    params_dict = zip(ml_model.state_dict().keys(), parameters)\n",
    "    \n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def get_params(ml_model):\n",
    "    return [val.cpu().numpy() for _, val in ml_model.state_dict().items()]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from flwr.common import Context\n",
    "from flwr.client import ClientApp\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    partition = fds.load_partition(partition_id, \"train\")\n",
    "    # partition into train/validation\n",
    "    partition_train_val = partition.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "    trainloader, testloader = get_mnist_dataloaders(partition_train_val, batch_size=32)\n",
    "\n",
    "    return FlowerClient(training_loader=trainloader, validation_loader=testloader).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List\n",
    "from flwr.common import Metrics\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
